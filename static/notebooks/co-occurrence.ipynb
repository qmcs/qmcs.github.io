{
 "metadata": {
  "name": "",
  "signature": "sha256:fa26d76ae6beb4b62271924c84a513a63ac24310d9757b78d4c84cc2043a9479"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Biggish data processing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Word similarity is the core notion in [distributional semantics](http://en.wikipedia.org/wiki/Distributional_semantics), where word meaning is represented as vectors. In such a vector space word similarity is modeled as the distance between two vectors. There are many datasets to evaluate distributional models, for example, [SimLex-999](http://www.cl.cam.ac.uk/~fh295/simlex.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The task\n",
      "\n",
      "Predict word similarity using co-occurrence based distributional semantic methods.\n",
      "\n",
      "We are going to exploit Zellig Harris\u2019s intuition, that semantically similar words tend to appear in similar contexts, in the following manner: given a large piece of text, for every word we count its co-occurrence with other words in a symmetric window of N (5 words before the word and 5 words after). The word in the middle of a window is referred as the target word, the words before and after as context words.\n",
      "\n",
      "Refer to the [Idea section](http://fowlercorpora.readthedocs.org/en/latest/quick_start.html#idea) for more details."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The data\n",
      "\n",
      "Download a bunch of books"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlretrieve\n",
      "\n",
      "f_names = tuple(urlretrieve('http://eecs.io/static/notebooks/{}'.format(f))[0]\n",
      "    for f in ['pg11.txt', 'pg2600.txt ', 'pg2554.txt', 'pg9296.txt', 'pg9798.txt', 'pg9881.txt']\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because of some restrictions, we are going to store functions and generators we define in files. The basic corpus reading generators are stored in `util.py`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file util.py\n",
      "from itertools import chain\n",
      "\n",
      "\n",
      "def read_words(f_name):\n",
      "    \"\"\"Read a file word by word.\"\"\"\n",
      "    with open(f_name) as f:\n",
      "        for line in f:\n",
      "            line.strip()\n",
      "            \n",
      "            # Tokenization is a difficult task,\n",
      "            # a word is anythin between two spaces.\n",
      "            for word in line.split():\n",
      "                yield word\n",
      "\n",
      "\n",
      "def clean_words(words):\n",
      "    \"\"\"Clean up words.\"\"\"\n",
      "    for word in words:\n",
      "        w = ''.join(ch for ch in word.lower() if ch.isalpha())\n",
      "\n",
      "        if w:\n",
      "            yield w\n",
      "\n",
      "        \n",
      "def corpus(f_names):\n",
      "    \"\"\"Treat a collection of files as a single resource.\"\"\"\n",
      "    return chain.from_iterable(clean_words(read_words(f)) for f in f_names)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting util.py\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Count how many words there are in the corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Before using generators and functionsdefined in files,\n",
      "# we enable the autoreloead extension, so IPython reloads\n",
      "# imported things when the source files are changed.\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "# We import the corpus() function defined previously in the file (module) util.py\n",
      "from util import corpus\n",
      "\n",
      "len(list(corpus(f_names)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "1130975"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Count how many distinct words there are."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(corpus(f_names)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "30745"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Co-occurrence\n",
      "\n",
      "Implement a fucntion that yields co-occurrence pairs for a given window. E.g.\n",
      "\n",
      "``` python\n",
      ">>> list(co_occurrence('abcde', 2))\n",
      "[\n",
      "    ('a', 'b'),\n",
      "    ('a', 'c'),\n",
      "    ('b', 'a'),\n",
      "    ('b', 'c'),\n",
      "    ('b', 'd'),\n",
      "    ('c', 'a'),\n",
      "    ('c', 'b'),\n",
      "    ('c', 'd'),\n",
      "    ('c', 'e'),\n",
      "    ('d', 'b'),\n",
      "    ('d', 'c'),\n",
      "    ('d', 'e'),\n",
      "    ('e', 'c'),\n",
      "    ('e', 'd'),\n",
      "]\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file cooccurrence.py\n",
      "from collections import deque\n",
      "from itertools import islice, chain\n",
      "\n",
      "\n",
      "def cooccurrence(words, window_size=5):\n",
      "    \"\"\"Yield co-occurence pairs in an iterable of words.\"\"\"\n",
      "    words = iter(words)\n",
      "\n",
      "    before = deque([], maxlen=window_size)\n",
      "    after = deque(islice(words, window_size))\n",
      "    \n",
      "    while after:\n",
      "        try:\n",
      "            word = next(words)\n",
      "        except StopIteration:\n",
      "            '''There are no more words.'''\n",
      "        else:\n",
      "            after.append(word)\n",
      "\n",
      "        target = after.popleft()\n",
      "\n",
      "        for context in chain(before, after):\n",
      "            yield target, context\n",
      "\n",
      "        before.append(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting cooccurrence.py\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cooccurrence import cooccurrence\n",
      "\n",
      "list(cooccurrence('abcd', 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[('a', 'b'),\n",
        " ('a', 'c'),\n",
        " ('b', 'a'),\n",
        " ('b', 'c'),\n",
        " ('b', 'd'),\n",
        " ('c', 'a'),\n",
        " ('c', 'b'),\n",
        " ('c', 'd'),\n",
        " ('d', 'b'),\n",
        " ('d', 'c')]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Count co-occurrence pairs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file count_cooccurrence.py\n",
      "import pandas as pd\n",
      "\n",
      "from cooccurrence import cooccurrence\n",
      "\n",
      "\n",
      "def count_cooccurrence(words):\n",
      "    \"\"\"Count co-occrence counts.\n",
      "    \n",
      "    :param iter words: an iterable of words.\n",
      "    \n",
      "    :return: a pandas.DataFrame where `target` and`context`\n",
      "             are the index columns and `count` is a data column.\n",
      "    \n",
      "    \"\"\"\n",
      "    frame = pd.DataFrame(\n",
      "        cooccurrence(words),\n",
      "        columns=('target', 'context'),\n",
      "    )\n",
      "    \n",
      "    frame['count'] = 1\n",
      "    \n",
      "    return frame.groupby(('target', 'context')).sum()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting count_cooccurrence.py\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It takes some time (12 seconds on my machine) to retrieve co-occurrence counts of a relatively small (1 million tokens) collection. In real life, much larger data sets are used, for example Wikipedia is about 2 billion tokes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from count_cooccurrence import count_cooccurrence\n",
      "\n",
      "%time cooccurrence_frame = count_cooccurrence(corpus(f_names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 10.8 s, sys: 1.61 s, total: 12.4 s\n",
        "Wall time: 12.6 s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cooccurrence_frame.sort('count', ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>target</th>\n",
        "      <th>context</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <th>the</th>\n",
        "      <td> 26898</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <th>the</th>\n",
        "      <td> 23753</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">the</th>\n",
        "      <th>of</th>\n",
        "      <td> 23753</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <td> 19269</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <th>the</th>\n",
        "      <td> 19269</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                count\n",
        "target context       \n",
        "the    the      26898\n",
        "of     the      23753\n",
        "the    of       23753\n",
        "       and      19269\n",
        "and    the      19269"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Parallelizing computation over multiple cores\n",
      "\n",
      "Most of modern computer CPUs have several cores, meaning that they can perform several computations at the same time.\n",
      "\n",
      "In our example, we could compute the co-occurrence counts independenly for each file in parallel and then sum them up. Note, however, that the result won't be identical to ```count_cooccurrence(corpus(f_names))```. Why? Does it matter? What approch is better?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before scaling our implementation to several CPU cores, we need to get familliar with the `map()` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In short, ``map()`` takes two arguments: a function and an iterable. It applies the funcion to each element in the passed iterable. For example, to lowercase a list of letters, one could write this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from string import lower\n",
      "\n",
      "list(map(lower, ['A', 'B', 'C']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['a', 'b', 'c']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To spread the computation over several cores, we can used ``multiprocessing.Pool`` that provides a map method as well:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from multiprocessing import Pool\n",
      "\n",
      "pool = Pool()\n",
      "list(pool.map(lower, ['A', 'B', 'C']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['a', 'b', 'c']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To spread the co-occurrence counting over several cores, we need to come up with at function that takes a file name and return a ``DataFrame`` with co-occurence counts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file count_cooccurrence_file.py\n",
      "from count_cooccurrence import count_cooccurrence\n",
      "from util import corpus\n",
      "\n",
      "\n",
      "def count_cooccurrence_file(f_name):\n",
      "    return count_cooccurrence(corpus([f_name]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting count_cooccurrence_file.py\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Serial implementaton"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from count_cooccurrence_file import count_cooccurrence_file\n",
      "\n",
      "# Read each file twice, to make parallel implementation impovement more evident!\n",
      "%time len(list(map(count_cooccurrence_file, f_names * 2)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 20 s, sys: 2.34 s, total: 22.3 s\n",
        "Wall time: 22.3 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parallel implementation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time len(list(pool.map(count_cooccurrence_file, f_names * 2)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 212 ms, sys: 222 ms, total: 434 ms\n",
        "Wall time: 13 s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Merging results together"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "map_result = list(pool.map(count_cooccurrence_file, f_names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cooccurrence_counts = (\n",
      "    pd.concat(map_result)\n",
      "    .groupby(level=('target', 'context'))\n",
      "    .sum()\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cooccurrence_counts.loc[['morning', 'evening']].sort('count', ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>target</th>\n",
        "      <th>context</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>morning</th>\n",
        "      <th>the</th>\n",
        "      <td> 251</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>evening</th>\n",
        "      <th>the</th>\n",
        "      <td> 240</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">morning</th>\n",
        "      <th>in</th>\n",
        "      <td> 110</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <td>  97</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>evening</th>\n",
        "      <th>that</th>\n",
        "      <td>  94</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "                 count\n",
        "target  context       \n",
        "morning the        251\n",
        "evening the        240\n",
        "morning in         110\n",
        "        and         97\n",
        "evening that        94"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Building a semantic space"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toy_space = (\n",
      "    cooccurrence_counts.loc[['morning', 'evening', 'john', 'mary', 'red', 'green']]  # select only some target words\n",
      "    .reset_index()  # get rid of index, so pivoting works\n",
      "    .pivot(index='target', columns='context', values='count')\n",
      "    .fillna(0)\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toy_space[['a', 'the', 'book', 'run']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>context</th>\n",
        "      <th>a</th>\n",
        "      <th>the</th>\n",
        "      <th>book</th>\n",
        "      <th>run</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>target</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>evening</th>\n",
        "      <td> 46</td>\n",
        "      <td> 240</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>green</th>\n",
        "      <td> 30</td>\n",
        "      <td>  43</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>john</th>\n",
        "      <td>  2</td>\n",
        "      <td>   5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mary</th>\n",
        "      <td> 68</td>\n",
        "      <td> 213</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>morning</th>\n",
        "      <td> 66</td>\n",
        "      <td> 251</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>red</th>\n",
        "      <td> 74</td>\n",
        "      <td>  72</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "context   a  the  book  run\n",
        "target                     \n",
        "evening  46  240     0    1\n",
        "green    30   43     0    0\n",
        "john      2    5     0    0\n",
        "mary     68  213     2    0\n",
        "morning  66  251     0    0\n",
        "red      74   72     0    0"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Semantic similarity"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import pairwise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairwise.cosine_similarity?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(pairwise.cosine_similarity(toy_space.values), index=toy_space.index, columns=toy_space.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>target</th>\n",
        "      <th>evening</th>\n",
        "      <th>green</th>\n",
        "      <th>john</th>\n",
        "      <th>mary</th>\n",
        "      <th>morning</th>\n",
        "      <th>red</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>target</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>evening</th>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.798374</td>\n",
        "      <td> 0.307136</td>\n",
        "      <td> 0.620545</td>\n",
        "      <td> 0.952338</td>\n",
        "      <td> 0.710514</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>green</th>\n",
        "      <td> 0.798374</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.240387</td>\n",
        "      <td> 0.560840</td>\n",
        "      <td> 0.785051</td>\n",
        "      <td> 0.876843</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>john</th>\n",
        "      <td> 0.307136</td>\n",
        "      <td> 0.240387</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.286026</td>\n",
        "      <td> 0.350444</td>\n",
        "      <td> 0.242568</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mary</th>\n",
        "      <td> 0.620545</td>\n",
        "      <td> 0.560840</td>\n",
        "      <td> 0.286026</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.620141</td>\n",
        "      <td> 0.559805</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>morning</th>\n",
        "      <td> 0.952338</td>\n",
        "      <td> 0.785051</td>\n",
        "      <td> 0.350444</td>\n",
        "      <td> 0.620141</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.705259</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>red</th>\n",
        "      <td> 0.710514</td>\n",
        "      <td> 0.876843</td>\n",
        "      <td> 0.242568</td>\n",
        "      <td> 0.559805</td>\n",
        "      <td> 0.705259</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "target    evening     green      john      mary   morning       red\n",
        "target                                                             \n",
        "evening  1.000000  0.798374  0.307136  0.620545  0.952338  0.710514\n",
        "green    0.798374  1.000000  0.240387  0.560840  0.785051  0.876843\n",
        "john     0.307136  0.240387  1.000000  0.286026  0.350444  0.242568\n",
        "mary     0.620545  0.560840  0.286026  1.000000  0.620141  0.559805\n",
        "morning  0.952338  0.785051  0.350444  0.620141  1.000000  0.705259\n",
        "red      0.710514  0.876843  0.242568  0.559805  0.705259  1.000000"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SimLex-999"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "simlex = pd.read_csv(\n",
      "    'https://bitbucket.org/dimazest/phd-buildout/raw/tip/notebooks/downloads/SimLex-999/SimLex-999.txt',\n",
      "    sep='\\t',\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "simlex.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word1</th>\n",
        "      <th>word2</th>\n",
        "      <th>POS</th>\n",
        "      <th>SimLex999</th>\n",
        "      <th>conc(w1)</th>\n",
        "      <th>conc(w2)</th>\n",
        "      <th>concQ</th>\n",
        "      <th>Assoc(USF)</th>\n",
        "      <th>SimAssoc333</th>\n",
        "      <th>SD(SimLex)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   old</td>\n",
        "      <td>         new</td>\n",
        "      <td> A</td>\n",
        "      <td> 1.58</td>\n",
        "      <td> 2.72</td>\n",
        "      <td> 2.81</td>\n",
        "      <td> 2</td>\n",
        "      <td> 7.25</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.41</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> smart</td>\n",
        "      <td> intelligent</td>\n",
        "      <td> A</td>\n",
        "      <td> 9.20</td>\n",
        "      <td> 1.75</td>\n",
        "      <td> 2.46</td>\n",
        "      <td> 1</td>\n",
        "      <td> 7.11</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.67</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  hard</td>\n",
        "      <td>   difficult</td>\n",
        "      <td> A</td>\n",
        "      <td> 8.77</td>\n",
        "      <td> 3.76</td>\n",
        "      <td> 2.21</td>\n",
        "      <td> 2</td>\n",
        "      <td> 5.94</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1.19</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> happy</td>\n",
        "      <td>    cheerful</td>\n",
        "      <td> A</td>\n",
        "      <td> 9.55</td>\n",
        "      <td> 2.56</td>\n",
        "      <td> 2.34</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5.85</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2.18</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  hard</td>\n",
        "      <td>        easy</td>\n",
        "      <td> A</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3.76</td>\n",
        "      <td> 2.07</td>\n",
        "      <td> 2</td>\n",
        "      <td> 5.82</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.93</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
        "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
        "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
        "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
        "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
        "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
        "\n",
        "   SimAssoc333  SD(SimLex)  \n",
        "0            1        0.41  \n",
        "1            1        0.67  \n",
        "2            1        1.19  \n",
        "3            1        2.18  \n",
        "4            1        0.93  "
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Useful links\n",
      "\n",
      "* http://nbviewer.ipython.org/github/rasbt/python_reference/blob/master/tutorials/multiprocessing_intro.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}