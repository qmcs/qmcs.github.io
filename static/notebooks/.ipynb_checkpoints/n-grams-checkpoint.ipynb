{
 "metadata": {
  "name": "",
  "signature": "sha256:fd98b0b2144901bd39ee935fd42fc6fe84f8b6b1645432e5be8e107054de3291"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Iterators"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A concept of iteration over containers is very powerfull. Python defines a protocol how iteration is performed. To see it in action, let's get the ASCII letters and enumarate them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from string import lowercase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lowercase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "'abcdefghijklmnopqrstuvwxyz'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``enumerate()`` enumerates a sequence of things. Appending ``?`` of ``??`` to a function, module or an object shows its help message."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "enumerate?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create an iterator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "enumerated_letters = enumerate(lowercase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``next()`` returns the next value from an iterator, which in case of ``enumerate()`` are ``(index, value)`` pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "(0, 'a')"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(1, 'b')"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way of accessing the values in a tuple is to assign all of them to variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "position, letter = next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we need to show something to a user which is a mix of text and data ``.format()`` is handy. Defining a string template with data placesholders and formating it with values avoid string concatenation using ``+``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'{letter} is enumerated as {position}'.format(letter=letter, position=position)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "'c is enumerated as 2'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In case a sequence of strings has to be joined use ``.join()``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ', '.join('{l} is enumerated as {p}'.format(l=l, p=p) for p, l in enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "d is enumerated as 3, e is enumerated as 4, f is enumerated as 5, g is enumerated as 6, h is enumerated as 7, i is enumerated as 8, j is enumerated as 9, k is enumerated as 10, l is enumerated as 11, m is enumerated as 12, n is enumerated as 13, o is enumerated as 14, p is enumerated as 15, q is enumerated as 16, r is enumerated as 17, s is enumerated as 18, t is enumerated as 19, u is enumerated as 20, v is enumerated as 21, w is enumerated as 22, x is enumerated as 23, y is enumerated as 24, z is enumerated as 25\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once an iterator is exhausted, a ``StopIteration`` exception is raised. However, it's possible to have infinite iterators."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "StopIteration",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-6592de41862c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerated_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mStopIteration\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Bigrams\n",
      "\n",
      "Given a sequence of words (or an iterable), ``bigrams()`` returns (yields) its bigrams. Here is another way of defining an iterator (actually a generator):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "\n",
      "\n",
      "def bigrams(words):\n",
      "    \"\"\"Bigram generated from a seuence of words.\n",
      "    \n",
      "    :param iter words: the sequence of words\n",
      "    :returns: adjacent word pairs\n",
      "    \n",
      "    \"\"\"\n",
      "    # In the very beginning, ther is no previous word,\n",
      "    # but we start with a bigram (None, words[0]) to\n",
      "    # indicate that words[0] has been seen in the beginning\n",
      "    # of the text.\n",
      "    previous = None\n",
      "    \n",
      "    # We also need to append None to the end of the text.\n",
      "    # itertools.chain chains iterables togetner\n",
      "    # (yes, a list in this regard is an iterable, as a\n",
      "    # string is and many other things.\n",
      "    for word in chain(words, [None]):\n",
      "        # A bigram is a previous word and the current word.\n",
      "        # yield is used to pause an iterator, \"return\" a value\n",
      "        # to the caller code and restore callers execution.\n",
      "        yield previous, word\n",
      "        \n",
      "        previous = word\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check wheter it works. Note that we don't actually care wheter words is a seuence of strings, it might be a seuence of anything."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(bigrams([1, 2, 3, 4]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "[(None, 1), (1, 2), (2, 3), (3, 4), (4, None)]"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# N-grams\n",
      "\n",
      "It would be cool to have a general generator for n-grams."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import deque\n",
      "\n",
      "\n",
      "def ngrams(words, ngram_len=2):\n",
      "    \"\"\"Generate ngrmas from a sequence of word.\n",
      "    \n",
      "    :param iter words: the sequence of words\n",
      "    :param int ngram_len: the lenght of the ngrams to be generated\n",
      "    \n",
      "    :returns: ngrams\n",
      "    \n",
      "    \"\"\"\n",
      "    # collecions.deque might me seen as a list of limited size.\n",
      "    # If an element apended when a deque is full, the elements\n",
      "    # from the other side of the deque is removed keeping the\n",
      "    # constant length of the deque.\n",
      "    #\n",
      "    # Addend dummy tokens marking the beginning of the sequence.\n",
      "    ngram = deque([None] * ngram_len, maxlen=ngram_len)\n",
      "    \n",
      "    for word in chain(words, [None] * (ngram_len - 1)):\n",
      "        ngram.append(word)\n",
      "        yield tuple(ngram)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(ngrams('abcd', ngram_len=3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[(None, None, 'a'),\n",
        " (None, 'a', 'b'),\n",
        " ('a', 'b', 'c'),\n",
        " ('b', 'c', 'd'),\n",
        " ('c', 'd', None),\n",
        " ('d', None, None)]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Read a file word by word\n",
      "\n",
      "We have a generator that produces ngrmas, but we are not able to get a sequence of words from a corpus, which so far is just a text file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_words(f_name):\n",
      "    \"\"\"Read a file word by word.\"\"\"\n",
      "    with open(f_name) as f:\n",
      "        for line in f:\n",
      "            line.strip()\n",
      "            \n",
      "            # Tokenization is a difficult task,\n",
      "            # so a token are split by space.\n",
      "            for word in line.split():\n",
      "                yield word\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use  Alice's Adventures in Wonderland by Lewis Carroll as a corpus. We download if from the Internet ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlretrieve\n",
      "\n",
      "\n",
      "f_name, _ = urlretrieve('http://www.gutenberg.org/cache/epub/11/pg11.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and store somewhere"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "'/var/folders/j5/m6pcb_9n6c1gqssrbtzmdmcc0000gn/T/tmpZQzbFl.txt'"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are ready to get a sequence of words from the corpus. It's too big to be shown here, so ony 10 words are shown."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import islice\n",
      "\n",
      "\n",
      "print ' '.join(islice(read_words(f_name), 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufeffProject Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll This\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can chain iterators as processing block of the information flow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for w1, w2 in islice(bigrams(read_words(f_name)), 10):\n",
      "    print w1, w2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None \ufeffProject\n",
        "\ufeffProject Gutenberg's\n",
        "Gutenberg's Alice's\n",
        "Alice's Adventures\n",
        "Adventures in\n",
        "in Wonderland,\n",
        "Wonderland, by\n",
        "by Lewis\n",
        "Lewis Carroll\n",
        "Carroll This\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Task\n",
      "\n",
      "Even though ```read_words()``` tokenizaion is very simple, we can filter out non letters. Lowercase words might be a good idea as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_words(words):\n",
      "    \"\"\"Filter out punctuation marks and other symbols from words.\n",
      "    \n",
      "    :param iter words: an iterable of words.\n",
      "    \n",
      "    :return: cleaned up words.\n",
      "    \n",
      "    \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Counting ngrams\n",
      "\n",
      "It would be cool if we managed to pump the bigrams to a database. Then counting elements would be a metter of seconds (given that you know SQL. Luckily, there is Pandas which let process data frames (tables) the way we want http://pandas.pydata.org/pandas-docs/stable/groupby.html."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_frame = pd.DataFrame(ngrams(read_words(f_name), ngram_len=2), columns=('Word 1', 'Word 2'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_frame.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        None</td>\n",
        "      <td>    \ufeffProject</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    \ufeffProject</td>\n",
        "      <td> Gutenberg's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Gutenberg's</td>\n",
        "      <td>     Alice's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     Alice's</td>\n",
        "      <td>  Adventures</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  Adventures</td>\n",
        "      <td>          in</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 173,
       "text": [
        "        Word 1       Word 2\n",
        "0         None     \ufeffProject\n",
        "1     \ufeffProject  Gutenberg's\n",
        "2  Gutenberg's      Alice's\n",
        "3      Alice's   Adventures\n",
        "4   Adventures           in"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Count unique bigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_frame['count'] = 1  # Create a new column"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts = bigram_frame.groupby(('Word 1', 'Word 2')).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.sort('count', ascending=False, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>said</th>\n",
        "      <th>the</th>\n",
        "      <td> 206</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <th>the</th>\n",
        "      <td> 152</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
        "      <th>a</th>\n",
        "      <td>  99</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>  90</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <th>the</th>\n",
        "      <td>  84</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 187,
       "text": [
        "               count\n",
        "Word 1 Word 2       \n",
        "said   the       206\n",
        "of     the       152\n",
        "in     a          99\n",
        "       the        90\n",
        "to     the        84"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Dictionary size"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = pd.DataFrame(read_words(f_name), columns=('Word', ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary['count'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = dictionary.groupby('Word').sum().sort('count', ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "6017"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 1664</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <td>  780</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <td>  773</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>a</th>\n",
        "      <td>  662</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <td>  596</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "      count\n",
        "Word       \n",
        "the    1664\n",
        "and     780\n",
        "to      773\n",
        "a       662\n",
        "of      596"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.plot().loglog()  # Check out Seaborn http://web.stanford.edu/~mwaskom/software/seaborn/ to get nicer plots."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "[]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEECAYAAADandTrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11601c190>"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Count bigrams that were seen more than n times"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bigram_counts[bigram_counts['count'] > 5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "462"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bigram_counts[bigram_counts['count'] > 4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "653"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Jont probability"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts['Joint probability'] = bigram_counts['count'] / bigram_counts['count'].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>Joint probability</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>said</th>\n",
        "      <th>the</th>\n",
        "      <td> 206</td>\n",
        "      <td> 0.006993</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <th>the</th>\n",
        "      <td> 152</td>\n",
        "      <td> 0.005160</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
        "      <th>a</th>\n",
        "      <td>  99</td>\n",
        "      <td> 0.003360</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>  90</td>\n",
        "      <td> 0.003055</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <th>the</th>\n",
        "      <td>  84</td>\n",
        "      <td> 0.002851</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "               count  Joint probability\n",
        "Word 1 Word 2                          \n",
        "said   the       206           0.006993\n",
        "of     the       152           0.005160\n",
        "in     a          99           0.003360\n",
        "       the        90           0.003055\n",
        "to     the        84           0.002851"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.loc['to'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>Joint probability</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 84</td>\n",
        "      <td> 0.002851</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>be</th>\n",
        "      <td> 48</td>\n",
        "      <td> 0.001629</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>herself,</th>\n",
        "      <td> 25</td>\n",
        "      <td> 0.000849</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>see</th>\n",
        "      <td> 23</td>\n",
        "      <td> 0.000781</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>get</th>\n",
        "      <td> 18</td>\n",
        "      <td> 0.000611</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "          count  Joint probability\n",
        "Word 2                            \n",
        "the          84           0.002851\n",
        "be           48           0.001629\n",
        "herself,     25           0.000849\n",
        "see          23           0.000781\n",
        "get          18           0.000611"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Condiitonal probability"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}