{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concept of iteration over containers is very powerfull. Python defines a protocol how iteration is performed. To see it in action, let's get the ASCII letters and enumarate them.\n",
    "\n",
    "Press shift+enter to execute a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from string import lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``enumerate()`` enumerates a sequence of things. Appending ``?`` of ``??`` to a function, module or an object shows its help message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enumerate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enumerated_letters = enumerate(lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``next()`` returns the next value from an iterator, which in case of ``enumerate()`` are ``(index, value)`` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'a')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerated_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'b')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerated_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of accessing the values in a tuple is to assign all of them to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position, letter = next(enumerated_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to show something to a user which is a mix of text and data ``.format()`` is handy. Defining a string template with data placesholders and formating it with values avoid string concatenation using ``+``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c is enumerated as 2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{letter} is enumerated as {position}'.format(letter=letter, position=position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case a sequence of strings has to be joined use ``.join()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d is enumerated as 3, e is enumerated as 4, f is enumerated as 5, g is enumerated as 6, h is enumerated as 7, i is enumerated as 8, j is enumerated as 9, k is enumerated as 10, l is enumerated as 11, m is enumerated as 12, n is enumerated as 13, o is enumerated as 14, p is enumerated as 15, q is enumerated as 16, r is enumerated as 17, s is enumerated as 18, t is enumerated as 19, u is enumerated as 20, v is enumerated as 21, w is enumerated as 22, x is enumerated as 23, y is enumerated as 24, z is enumerated as 25\n"
     ]
    }
   ],
   "source": [
    "print ', '.join('{l} is enumerated as {p}'.format(l=l, p=p) for p, l in enumerated_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an iterator is exhausted, a ``StopIteration`` exception is raised. However, it's possible to have infinite iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6592de41862c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerated_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(enumerated_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams\n",
    "\n",
    "Given a sequence of words (or an iterable), ``bigrams()`` returns (yields) its bigrams. Here is another way of defining an iterator (actually a generator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "def bigrams(words):\n",
    "    \"\"\"Bigram generated from a seuence of words.\n",
    "    \n",
    "    :param iter words: the sequence of words\n",
    "    :returns: adjacent word pairs\n",
    "    \n",
    "    \"\"\"\n",
    "    # In the very beginning, ther is no previous word,\n",
    "    # but we start with a bigram (None, words[0]) to\n",
    "    # indicate that words[0] has been seen in the beginning\n",
    "    # of the text.\n",
    "    previous = None\n",
    "    \n",
    "    # We also need to append None to the end of the text.\n",
    "    # itertools.chain chains iterables togetner\n",
    "    # (yes, a list in this regard is an iterable, as a\n",
    "    # string is and many other things.\n",
    "    for word in chain(words, [None]):\n",
    "        # A bigram is a previous word and the current word.\n",
    "        # yield is used to pause an iterator, \"return\" a value\n",
    "        # to the caller code and restore callers execution.\n",
    "        yield previous, word\n",
    "        \n",
    "        previous = word\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check wheter it works. Note that we don't actually care wheter words is a seuence of strings, it might be a seuence of anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 1), (1, 2), (2, 3), (3, 4), (4, None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams([1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n",
    "It would be cool to have a general generator for n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "def ngrams(words, ngram_len=2):\n",
    "    \"\"\"Generate ngrmas from a sequence of word.\n",
    "    \n",
    "    :param iter words: the sequence of words\n",
    "    :param int ngram_len: the lenght of the ngrams to be generated\n",
    "    \n",
    "    :returns: ngrams\n",
    "    \n",
    "    \"\"\"\n",
    "    # collecions.deque might be seen as a list of limited size.\n",
    "    # If an element apended when a deque is full, the elements\n",
    "    # from the other side of the deque is removed keeping the\n",
    "    # constant length of the deque.\n",
    "    #\n",
    "    # Addend dummy tokens marking the beginning of the sequence.\n",
    "    ngram = deque([None] * ngram_len, maxlen=ngram_len)\n",
    "    \n",
    "    for word in chain(words, [None] * (ngram_len - 1)):\n",
    "        ngram.append(word)\n",
    "        yield tuple(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, None, 'a'),\n",
       " (None, 'a', 'b'),\n",
       " ('a', 'b', 'c'),\n",
       " ('b', 'c', 'd'),\n",
       " ('c', 'd', None),\n",
       " ('d', None, None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams('abcd', ngram_len=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read a file word by word\n",
    "\n",
    "We have a generator that produces ngrmas, but we are not able to get a sequence of words from a corpus, which so far is just a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_words(f_name):\n",
    "    \"\"\"Read a file word by word.\"\"\"\n",
    "    with open(f_name) as f:\n",
    "        for line in f:\n",
    "            line.strip()\n",
    "            \n",
    "            # Tokenization is a difficult task,\n",
    "            # a word is anythin between two spaces.\n",
    "            for word in line.split():\n",
    "                yield word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use  Alice's Adventures in Wonderland by Lewis Carroll as a corpus.\n",
    "\n",
    "Some other books are:\n",
    "\n",
    "* War and Peace by graf Leo Tolstoy http://eecs.io/static/notebooks/pg2600.txt 566,316 words\n",
    "* Crime and Punishment by Fyodor Dostoyevsky http://eecs.io/static/notebooks/pg2554.txt 206,528 words\n",
    "* Alice's Adventures in Wonderland by Lewis Carroll http://eecs.io/static/notebooks/pg11.txt 29,461 words\n",
    "* Clarissa Harlowe; or the history of a young lady — Volume 1 by Samuel Richardson http://eecs.io/static/notebooks/pg9296.txt 109,997 words\n",
    "* Clarissa Harlowe; or the history of a young lady — Volume 2 by Samuel Richardson http://eecs.io/static/notebooks/pg9798.txt 110,407 words\n",
    "* Clarissa Harlowe; or the history of a young lady — Volume 3 by Samuel Richardson http://eecs.io/static/notebooks/pg9881.txt 109,620 words\n",
    "\n",
    "We download it from the Internet ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import urlretrieve\n",
    "\n",
    "\n",
    "f_name, _ = urlretrieve('http://eecs.io/static/notebooks/pg11.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and store it somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/j5/m6pcb_9n6c1gqssrbtzmdmcc0000gn/T/tmp0LsuU_.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to get a sequence of words from the corpus. It's too big to be shown here, so ony 10 words are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll This\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "print ' '.join(islice(read_words(f_name), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chain iterators as processing block of the information flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ﻿Project\n",
      "﻿Project Gutenberg's\n",
      "Gutenberg's Alice's\n",
      "Alice's Adventures\n",
      "Adventures in\n",
      "in Wonderland,\n",
      "Wonderland, by\n",
      "by Lewis\n",
      "Lewis Carroll\n",
      "Carroll This\n"
     ]
    }
   ],
   "source": [
    "for w1, w2 in islice(bigrams(read_words(f_name)), 10):\n",
    "    print w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: clean up the words\n",
    "\n",
    "Even though ```read_words()``` tokenizaion is very simple, we can filter out non letters. Lowercase words might be a good idea as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_words(words):\n",
    "    for word in words:\n",
    "        yield word.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting ngrams\n",
    "\n",
    "It would be cool if we managed to pump the bigrams to a database. Then counting elements would be a metter of seconds (given that you know SQL. Luckily, there is Pandas which let process data frames (tables) the way we want http://pandas.pydata.org/pandas-docs/stable/groupby.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_frame = pd.DataFrame(ngrams(clean_words(read_words(f_name)), ngram_len=2), columns=('Word 1', 'Word 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>        None</td>\n",
       "      <td>    ﻿project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>    ﻿project</td>\n",
       "      <td> gutenberg's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> gutenberg's</td>\n",
       "      <td>     alice's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>     alice's</td>\n",
       "      <td>  adventures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  adventures</td>\n",
       "      <td>          in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 1       Word 2\n",
       "0         None     ﻿project\n",
       "1     ﻿project  gutenberg's\n",
       "2  gutenberg's      alice's\n",
       "3      alice's   adventures\n",
       "4   adventures           in"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count unique bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_frame['count'] = 1  # Create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_counts = bigram_frame.groupby(('Word 1', 'Word 2')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_counts.sort('count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <th>the</th>\n",
       "      <td> 207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <td> 154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
       "      <th>a</th>\n",
       "      <td> 101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>  92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <td>  84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count\n",
       "Word 1 Word 2       \n",
       "said   the       207\n",
       "of     the       154\n",
       "in     a         101\n",
       "       the        92\n",
       "to     the        84"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = pd.DataFrame(clean_words(read_words(f_name)), columns=('Word', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = dictionary.groupby('Word').sum().sort('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5581"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td> 1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>  833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>  782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>  670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>  610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "Word       \n",
       "the    1777\n",
       "and     833\n",
       "to      782\n",
       "a       670\n",
       "of      610"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEECAYAAADandTrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAGTlJREFUeJzt3Xt0ldWZx/HvkwACQQ2gRS6BKEIrlmnaccQOg5wZrStW\n",
       "EWmxmFVAvLadoYuxavE2EKoWrWPRaql2EEKtcrNOFQoiKscqaIWKSAexoI1cFKjchCI1JHv+2McQ\n",
       "QgInOefkfc97fp+1spL95pw3T1j6sHneZ+9tzjlERCS75QUdgIiIpE7JXEQkApTMRUQiQMlcRCQC\n",
       "lMxFRCJAyVxEJAKUzEVEIkDJXEQkAjKSzM2swMxWmNlFmbi/iIgcLlMz8x8CczJ0bxERqSepZG5m\n",
       "081sm5mtqXe91MzWmdl6MxufuPY1YC3w1/SHKyIiDbFk9mYxs0HAPuBXzrn+iWv5wDvA+cAWYAVQ\n",
       "BnwbKAD6AZ8Aw5w2gBERyahWybzIOfeymRXXu3w2sME5VwlgZrOBoc652xPjK4C/KpGLiGReUsm8\n",
       "Ed2BTXXGm4EBnw2cczNTuLeIiDRBKsk8pRm3mbkrrriC4uJiAAoLCykpKSEWiwEQj8cBNNZYY41z\n",
       "ehyPx6moqACguLiYSZMm4Zwz6kmqZg6QKLPMr1MzPwcod86VJsa3ADXOuXuSvJ8qMCIiTWRmDSbz\n",
       "VFoTVwJ9zKzYzNoAI4BnmnKD8vLy2r+BRESkcfF4nPLy8ka/n2w3yyxgMNAZ2A5McM7NMLMLgfuB\n",
       "fOBR59zkZAPTzFxEpOkam5knXWZJNyVzEZGmy0SZJWUqs4iIJCctZZZM0MxcJLeYHTGZlGNoKEc2\n",
       "NjNPpTVRRKRJNIFLXlP/8lOZRUQkC6jMIiKhkCgPBB1G1mjszyuUD0BFRCQ9lMxFRFpYcXExL774\n",
       "YlrvqZq5iEgLa07J6Vg1c5xzgXz4Hy0iuSLM/89v3LjRDRs2zJ188smuc+fObuzYsa6mpsbdcccd\n",
       "rlevXu5zn/ucGz16tNuzZ49zzrmlS5e6Hj16HHaPXr16uRdeeME559zEiRPdZZdd5kaPHu2OP/54\n",
       "d+aZZ7qVK1c655wbOXKky8vLc+3atXMdOnRw9957b4MxNfbnlbh+RE5VmUVEclp1dTUXX3wxp556\n",
       "Ku+//z4ffPABl19+OTNmzGDmzJnE43Hee+899u3bx9ixYxu9T/1Wwvnz51NWVsaePXu45JJLat/7\n",
       "2GOP0bNnTxYsWMDevXu58cYb0/J7KJmLSE57/fXX+fDDD7n33ntp164dbdq0YeDAgTz++OPccMMN\n",
       "FBcXU1BQwOTJk5k9ezY1NTVJ3XfQoEGUlpZiZowcOZLVq1dn9PcIdNFQeXk5sVisdg9fEcld6Vog\n",
       "2tTux02bNtGrVy/y8g6f23744Yf06tWrdtyzZ08OHjzItm3bkrpvly5dar9u3749Bw4coKam5oif\n",
       "k6x4PH7UZ4yBPwBVIhcR8Ek4HR9NVVRUxMaNG6murj7serdu3aisrKwdb9y4kVatWtGlSxcKCgrY\n",
       "v39/7feqq6v561+TP8O+OVsbxGKxoz4AVZlFRHLagAED6Nq1KzfffDP79+/nwIEDLFu2jLKyMqZM\n",
       "mUJlZSX79u3j1ltv5fLLLycvL4++ffty4MABFi5cSFVVFXfeeSd///vfk/6ZXbp04d13303r76Fk\n",
       "LiI5LS8vj/nz57NhwwZ69uxJUVER8+bN46qrrmLUqFGce+65nHbaabRv354HH3wQgBNPPJGpU6dy\n",
       "zTXX0KNHDzp06EBRUVHtPc3siNl33fEtt9zCnXfeSceOHfnpT3+alt9Dy/lFpEVoOX/TaDm/iEgO\n",
       "CvwBqFaAiogcm3ZNFJFQUJmlaVRmERHJQUrmIiIRoGQuIhIBSuYiIhGgA51FpMU0Zxm7JEcbbYlI\n",
       "i1AnS2qOtdGWWhNFRLKIWhNFRCJMyVxEJAKUzEVEIkDJXEQkApTMRUQiQMlcRCQClMxFRCJAyVxE\n",
       "JAJ0OIWISBbQ4RQiIhGiFaAiIhGmZC4iEgFK5iIiEaBkLiISAUrmIiIRoGQuIhIBSuYiIhGgZC4i\n",
       "EgFK5iIiEZD2ZG5mXzCzX5jZXDO7Ot33FxGRI2VsOb+Z5QGznXPfauT7Ws4vItJEKS3nN7PpZrbN\n",
       "zNbUu15qZuvMbL2Zja9zfQjwO2B2qoGLiMixJTUzN7NBwD7gV865/olr+cA7wPnAFmAFUOace7vO\n",
       "+552zg1t5J6amYuINFFjM/NWybzZOfeymRXXu3w2sME5V5n4AbOBoWb2OeAbQFtgaQoxi4hIkpJK\n",
       "5o3oDmyqM94MDHDOvQS8lMwNxowZQ3FxMQCFhYWUlJQQi8UAavc511hjjTXO5XE8HqeiogKgNl82\n",
       "JOkHoImZ+fw6ZZZvAqXOuWsT45H4ZP79JO+nMouISBNlYj/zLUBRnXERfnYuIiItLJVkvhLoY2bF\n",
       "ZtYGGAE805Qb6Ng4EZHkxNNxbJyZzQIGA52B7cAE59wMM7sQuB/IBx51zk1ONjCVWY5UXQ0jRkCn\n",
       "Tv6jc+eGP3fqBMcdF3S0IhKExsosOgM0RA4ehN/+FnbsgJ07G/+8cye0aXPshP/Z1yedBH36QH5+\n",
       "0L+hiKQqpdbETCkvLycWi9U+wc11rVrB8OHHfp1zsG9f48l+82Z4661D423b4OOP4aKLYMgQuOAC\n",
       "OP74zP8+IpI+8Xj8qGVpzcxzRGUlLFgAzzwDr74KAwf6xD5kCPTsGXR0IpIslVmk1scfw3PPwfz5\n",
       "sHAhdOsGl1ziE/tZZ0Ge9tIUCa1MtCamTN0swTjhBF/OmTkTtm6FqVOhqgrGjIHu3eGaa+Cpp3yJ\n",
       "RkTCIS3dLJmgmXk4vfuun7EvXgzLlvkHp//2b/5j0CDo0CHoCEVym8os0mSffgorVsCLL/qPFSvg\n",
       "S186lNwHDvRdNSLScpTMJWWffALLl/vEvmQJ7NoFU6b4Lhk74j8tEcmEUCbziRMnqjUxiz37LFx/\n",
       "PfTq5ZP6GWcEHZFIdH3Wmjhp0qTwJXPNzLNfVRX8/Odw110wciRMnAiFhUFHJRJdoexmkezXujX8\n",
       "53/C2rWwfz984QvwyCN+awIRaTmamUtarVoF//7vvsXx17+Gtm2DjkgkWkI5M1efefR8+csQj/t9\n",
       "YEpLYffuoCMSiQb1mUsgamr8w9GlS2HRIj9TF5HUhXJmLtGVlwf33w/f/rbvR1+3LuiIRKIt0F0T\n",
       "JdrMYPx4OOUUiMVg1iwtNBLJFJVZpEUsWuQfjG7Z4vdZ79HDfwwe7K8rwYskJ5SLhpTMc091td/c\n",
       "a/Nm2LQJKirgnXfgvvv8ro1aSSpydKFM5loBKnBoJWmPHvDAA9CvX9ARiYSPVoBKVqiqgl/8Au64\n",
       "A+6+G666SrN0kYaEcmauZC71vf2232v9rLP8PusFBUFHJBIuSuaSNf72N/je9+CNN+Cyy/we6gUF\n",
       "8PWv64g7ESVzySrOwW9+A2vW+MOr//IXf/KRFgxLrlMyl6x28KDfxOvRR307o0iu0gpQyWqtWsFt\n",
       "t8GPfhR0JCLhpI22JGuMHOnLLa+8EnQkIi1PG21JpEybBvPm+QOnRXKRauYSCZ9+Cn36wHXXwWmn\n",
       "Hdr3RT3pkiuUzCUyXnoJ5s713S2rV0P//n5bgHbtgo5MJPOUzCWSDhyAq6+G9evh6aeha9egIxLJ\n",
       "LHWzSCS1beuPpxs61K8afeGFoCMSCYZm5hIZzz8Po0fDJZf4enqnTr43/YtfhMLCoKMTSQ+VWSQn\n",
       "bN3qFxbt3g0ffeT3elm3Dq69Fm69FTp2DDpCkdQomUvO+vBDv+DojTdg1Sp1vkh2C2XNXIuGpCV0\n",
       "7epn61VV8OKLQUcj0jxaNCSS8Mgj8LvfwTPPBB2JSPOpzCI5b/9+v4XuH/4AvXsHHY1I84SyzCLS\n",
       "ktq3h7FjYeBAGDXK19JFokIzc8kpzsF778HDD8OSJX416YknBh2VSPI0MxfBd7L07g0/+QkMGuQ/\n",
       "Zs70e76IZDPNzCVn1dTAggXw4IN+tv7DH8L556ueLuGmB6AiR/HCC759cckSmDABvv/9oCMSaZiS\n",
       "uUgSKivhwguhe3e46y4YMCDoiEQOp5q5SBKKi+HNN2HECBg+HPbuDToikeRoZi7SiCuu8A9Mf/xj\n",
       "6NYt6GhEPM3MRZrovvv85/79QbtOSNhlZGZuZkOBi4ATgEedc0saeI1m5pIVli6FSy/1e6effjqc\n",
       "dBI88IAvyYi0tEAegJpZIfDfzrlrGviekrlkjX374OOP/YlGCxbAH//o90/P079tpYWlXGYxs+lm\n",
       "ts3M1tS7Xmpm68xsvZmNr/e224GHmheySHh06ODr5oMHw913+33TX3016KhEDmnKvGIGUFr3gpnl\n",
       "45N1KdAPKDOzM8y7B1jknHszbdGKhEB+PgwZ4nvSRcIi6WTunHsZ2FXv8tnABudcpXOuCpgNDAXG\n",
       "AucBw83sO+kKViQsvvY1eO65oKMQOaRViu/vDmyqM94MDHDOfR948FhvHjNmDMWJp0iFhYWUlJQQ\n",
       "i8UAag+t0FjjMI5rauK89RaMGxfjpptgw4ZwxadxdMbxeJyKigqA2nzZkCY9ADWzYmC+c65/YvxN\n",
       "oNQ5d21iPJJDyfxY99IDUMlq77wDFRV+G4B774WzzoJ+/XQsnWRWpvrMtwBFdcZF+Nm5SOR9/vMw\n",
       "eTLMnQtz5vjSyyOPBB2V5KpUk/lKoI+ZFZtZG2AEkPShXDoDVKIgFoOFC/1WutOmBR2NRFU8XWeA\n",
       "mtksYDDQGdgOTHDOzTCzC4H7gXz8AqHJSd5PZRaJlOpqfyzd8OG+3PLVr8IXv6hedEkv7Zoo0gL+\n",
       "/GeYNw/WrIHly+Gf/gnuucevHBVJh8aSeardLCkpLy8nFovVPsEVyXZ9+8Jtt/mvP/nEb9J1zjk+\n",
       "qZ90EpSV+S129ZBUmioejx+1LK2ZuUiG7d0LixfDjh0wZQqMHAm33x50VJKtVGYRCYFNm+ArX4H5\n",
       "8/2MXaSpQrkFrrpZJNcUFcGMGX47gAkTYOPGoCOSbJG2bpZ008xcctmWLXDTTfDb38K770LXrkFH\n",
       "JNlCZRaREBo3Dn75S/joIygoCDoayQahLLOI5LoHHvAll969fVIXaS61JooE7Ikn4Nln4eqroarK\n",
       "f27bNuioJGzUmiiSJVauhGuv9S2MN90E3/0utG4ddFQSNqqZi2SBmhpYtAj+67/g/PPhJz8JOiIJ\n",
       "GyVzkSyyZYvf1+XAAfiP//C7M2qWLhDSB6DqMxdpWPfuvsNl9WpYtsyXXTT3yW3qMxfJcrt2wcCB\n",
       "sH27b2Xs3x8uvTToqCQooZyZi8ixdewIa9fCr37lyy4jRqiNUY6kmblIllm0CCZNgtdeCzoSCYJm\n",
       "5iIRcd55/vzRW2+FrVthz56gI5Iw0ANQkSzTpg28/DK88gqUlECPHnDHHbB7d9CRSSbpAahIxD3/\n",
       "vD/NaPVqWLoUzjwz6Igkk9RnLhJhBw/CD34A8bhP6jrJKLqUzEUirqYGiov9oRdz5wYdjWSKkrlI\n",
       "Dti5E047ze/zokOko0ndLCI5oFMnGDPGrxiV3KKZuUjE7N7tZ+f5+f5h6KxZOskoSkI5M1drokj6\n",
       "FRbC5s1+1WhBgU/sjz0Gf/5z0JFJKtSaKJLjfvYzeOop+OADmDMHvvzloCOSVOgBqEgO+/RTf4LR\n",
       "ypUwbBj86EfQKtBzxqS5QllmEZGW0aYNPPwwjB0Ljz8Ow4dDZWXQUUk6aWYukmNWrYJbbvH7pT/5\n",
       "pO9Nl+yhmbmIAL5mPmMGnHwyfOMb8Ic/BB2RpIOSuUgO6toVHn0UvvQlX0t//vmgI5JUqcwiksN2\n",
       "7IAJE+D3v/fbAIwb588elfBSN4uINGjHDvjf/4Wnn/Ybdg0a5FeRdusWdGTSECVzETmq//s/eOIJ\n",
       "eO45P0sfP97vlS7h0lgyD7TTtLy8nFgsRiwWCzIMEcEv/b/rLn949G23+W0Bpk2D444LOjIBvwL0\n",
       "aCvmNTMXkSO8/jpccAF06OC3BpDwUGuiiCTt7LNh1y7YsgUeeijoaCQZSuYi0iAzuPtuX2pZuTLo\n",
       "aORYVGYRkUZt3QrXXQfbt8NrrwUdjYC6WUSkmTZvhlNPhS5doHNnePNNnTEaJCVzEWm27dv9zov9\n",
       "+sHUqT6pl5YqqQdByVxEUnbzzbB+PSxcCO+9pxOMgqBkLiJpc+aZfrfFa6+FSy8NOprcotZEEUmb\n",
       "6dOhZ0+/BYCEg2bmItIsCxbA5ZfDKadA+/awfLlfZCSZ1WIzczM71cymmdm8dN9bRMLj61+H1avh\n",
       "2WfhwAGdXBS0tCdz59xfnHPXpPu+IhIueXnQuzecfjp8/vPwL//iD7xYsCDoyHJTUsnczKab2TYz\n",
       "W1PveqmZrTOz9WY2PjMhikjYPfmk73IpK4M//SnoaHJTsjPzGUBp3Qtmlg88lLjeDygzszPSG56I\n",
       "ZIPjjvOz8tNPhylT/NF0X/kKrFgRdGS5I6lk7px7GdhV7/LZwAbnXKVzrgqYDQw1s05m9jBQotm6\n",
       "SG657jpfQ58+3bcurl4ddES5I5X9zLsDm+qMNwMDnHM7ge+mFJWIZKW2bf2sHKBPH5g71+/vMm4c\n",
       "HH98sLFFXSrJPOW+wjFjxlBcXAxAYWEhJSUltQdVfLYJu8Yaa5yd4759oV27GNOmwYknxunfP1zx\n",
       "Zcs4Ho9TUVEBUJsvG5J0n7mZFQPznXP9E+NzgHLnXGlifAtQ45y7J8n7qc9cJAdcfDF85zswZEjQ\n",
       "kURDJvrMVwJ9zKzYzNoAI4BnUrifiERQ9+7wrW/BCSf4j2vUuJwRybYmzgKWA33NbJOZXemcOwiM\n",
       "BRYDa4E5zrm3m/LDy8vLa/85ISLRNHUqbNvmt9KdMwfeeSfoiLJTPB6nvLy80e9rOb+ItJhVq2DU\n",
       "KHj++UPXCgr0cLQpGiuzpPIANGXl5eXEYrHaor+IRFu3bvDxx1BS4sc1NX5fF20FcGzxePyolQzN\n",
       "zEUkMHv2QFGRT/CSHG2BKyKh07497N8PmtelTjNzEQlUhw5+G926R9CNGgUTJgQXU5ipZi4iobRh\n",
       "A+zde2i8ZAksXhxcPGGlmrmIZJUlS+Ceew7veJFDQjkzFxGpr6AAdu6E998/dC0/3y8+siNSmHxG\n",
       "ZRYRCZUePXx3y7nnHrq2dSv8/vcwYEBwcQVNZRYRyXoXXAA33ug/5zq1JopI1mrb1p8zKo1TMheR\n",
       "0FMyPzaVWUQk9K680u/r0qPH4ddvugkGDw4mpqCEsptFD0BFJBnl5bBmzeHXKirgtddyJ5nrAaiI\n",
       "RNLtt/vyy+23Bx1Jy9IDUBGJlDZt4NNPg44iPJTMRSQrKZkfTitARSQrtW7tTy1asODI7+Xlwb/+\n",
       "K7Rr1/JxBUUPQEUkKw0YAEuXwsMPH/m9FStg+nS46KKWjytT9ABURHLOsGEwerT/HDV6ACoiOaN1\n",
       "a6iqCjqKlqVkLiKR06qVkrmISNZr3RoOHgw6ipalZC4ikZOLM3O1JopI5LRuDa+/Dh07Hvu155zj\n",
       "D77IdmpNFJHIueACePxxeOKJo79u3Tq49FK4666WiSsVak0UEWnE5Mmwe7c/czRbqDVRRKSe/Hyo\n",
       "rg46ivRQMheRnKVkLiISAUrmIiIRoGQuIhIBSuYiIhGgZC4iEgFRSuZaASoiOSs/H954AyZNat77\n",
       "y8qgb9/0xtRcWgEqIjnrvPOgshJqapr+3mefhRNOaLlkrhWgIiIZcP31UFQEP/hBy/5crQAVEUmj\n",
       "vLzmzegzRclcRKQZ8vIgTMUFJXMRkWYw08xcRCTrqcwiIhIBKrOIiESAyiwiIhGgMouISASozCIi\n",
       "EgFhm5mnfTm/mRUAU4G/A3Hn3DGOVBURyT65UDP/BjDXOXcdcEkG7i8iErisLLOY2XQz22Zma+pd\n",
       "LzWzdWa23szGJy53BzYlvo7I5pIiIocLW5kl2Zn5DKC07gUzywceSlzvB5SZ2RnAZqCoifcXEckq\n",
       "WVlmcc69DOyqd/lsYINzrtI5VwXMBoYCTwHfNLOpwDPpDFZEJCzCVmZJ5QFo3XIK+Bn5AOfcfuCq\n",
       "lKISEQm5Vq3gySdh7dqgI/FSSeYp/51kZnXP94g75+Kp3lNEpCXccIP/yDQziwGxOpcmNvS6VJL5\n",
       "Fg7Vxkl8vTnZNze0ubqIiBwuMcmN17lU3tDrUnlAuRLoY2bFZtYGGIFq5CIigUi2NXEWsBzoa2ab\n",
       "zOxK59xBYCywGFgLzHHOvZ25UEVEpDGBnQEqIiLpoz5wiTwzm2Jm4+qMF5vZ/9QZ32dm1zfjvjEz\n",
       "m5+uOEVSoWQuueAV4J8BzCwP6Ixf6PaZrwLLjnWTxHtFQkn/cUoueBWfsAHOBP4E7DWzQjM7DjgD\n",
       "KDSzVWb2lpk9mnioj5lVmtndZvZH4LLEFhZvJ8bDgvhlRBqiZC6R55z7ADhoZkX4pP4q8Hri67OA\n",
       "9cA04DLn3D/gW3a/99nbgY+cc/8IPA38Erg4MT6FNKy3EEkHJXPJFcvxpZZ/xifzVxNffxW/PuI9\n",
       "59yGxGtnAufWee+cxOcvAH9xzr2bGP8a0HoJCQUlc8kVy4CBQH9gDfAah5J7nMOTsnH4jPtvjdxT\n",
       "iVxCQ8lccsVy4GJgh/N2AYX4mflvgGIz65147SjgpQbusS7xutMS47IMxyySNCVzyRV/wnexvFbn\n",
       "2lvAbufcFuBKYJ6ZvQUcBB5OvKZ2hu6cOwBcB/wu8QB0G6qZS0ho0ZCISARoZi4iEgFK5iIiEaBk\n",
       "LiISAUrmIiIRoGQuIhIBSuYiIhGgZC4iEgFK5iIiEfD/r3KZ07uhx9AAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115f79190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary.plot().loglog()  # Check out Seaborn http://web.stanford.edu/~mwaskom/software/seaborn/ to get nicer plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count bigrams that were seen more than n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_counts[bigram_counts['count'] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_counts[bigram_counts['count'] > 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_counts['Joint probability'] = bigram_counts['count'] / bigram_counts['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Joint probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <th>the</th>\n",
       "      <td> 207</td>\n",
       "      <td> 0.007026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <td> 154</td>\n",
       "      <td> 0.005227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
       "      <th>a</th>\n",
       "      <td> 101</td>\n",
       "      <td> 0.003428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>  92</td>\n",
       "      <td> 0.003123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <td>  84</td>\n",
       "      <td> 0.002851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  Joint probability\n",
       "Word 1 Word 2                          \n",
       "said   the       207           0.007026\n",
       "of     the       154           0.005227\n",
       "in     a         101           0.003428\n",
       "       the        92           0.003123\n",
       "to     the        84           0.002851"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Joint probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td> 84</td>\n",
       "      <td> 0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td> 49</td>\n",
       "      <td> 0.001663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herself,</th>\n",
       "      <td> 25</td>\n",
       "      <td> 0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td> 23</td>\n",
       "      <td> 0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td> 18</td>\n",
       "      <td> 0.000611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count  Joint probability\n",
       "Word 2                            \n",
       "the          84           0.002851\n",
       "be           49           0.001663\n",
       "herself,     25           0.000849\n",
       "see          23           0.000781\n",
       "get          18           0.000611"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.loc['to'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condiitonal probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Joint probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <th>the</th>\n",
       "      <td> 207</td>\n",
       "      <td> 0.007026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <td> 154</td>\n",
       "      <td> 0.005227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
       "      <th>a</th>\n",
       "      <td> 101</td>\n",
       "      <td> 0.003428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>  92</td>\n",
       "      <td> 0.003123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <td>  84</td>\n",
       "      <td> 0.002851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  Joint probability\n",
       "Word 1 Word 2                          \n",
       "said   the       207           0.007026\n",
       "of     the       154           0.005227\n",
       "in     a         101           0.003428\n",
       "       the        92           0.003123\n",
       "to     the        84           0.002851"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_counts['Word 1 count'] = dictionary.loc[bigram_counts.index.get_level_values('Word 1')]['count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_counts['Conditional probability'] = bigram_counts['count'] / bigram_counts['Word 1 count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Joint probability</th>\n",
       "      <th>Word 1 count</th>\n",
       "      <th>Conditional probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td> 57</td>\n",
       "      <td> 0.001935</td>\n",
       "      <td> 518</td>\n",
       "      <td> 0.110039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td> 51</td>\n",
       "      <td> 0.001731</td>\n",
       "      <td> 518</td>\n",
       "      <td> 0.098456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td> 28</td>\n",
       "      <td> 0.000950</td>\n",
       "      <td> 518</td>\n",
       "      <td> 0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td> 28</td>\n",
       "      <td> 0.000950</td>\n",
       "      <td> 518</td>\n",
       "      <td> 0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td> 19</td>\n",
       "      <td> 0.000645</td>\n",
       "      <td> 518</td>\n",
       "      <td> 0.036680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  Joint probability  Word 1 count  Conditional probability\n",
       "Word 2                                                                 \n",
       "had        57           0.001935           518                 0.110039\n",
       "was        51           0.001731           518                 0.098456\n",
       "said       28           0.000950           518                 0.054054\n",
       "went       28           0.000950           518                 0.054054\n",
       "could      19           0.000645           518                 0.036680"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.loc['she'].sort('Conditional probability', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get two corpora drawen from a different domain (for example, Russian classics, and novels about Clarissa), and divide each to a training and a test set. Build language models based on the training data for each domain. Then calcualte the corss-entropy figures for the test sets using both the language model trained on that domain, and the other language model. How much do the cross-entropy estimates differ?\n",
    "\n",
    "`This is Exercise 6.8 from Manning, Christopher D. \"Foundations of statistical natural language processing\". Ed. Hinrich Schütze. MIT press, 1999.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different tokenisation methods. Try to implement the experiments in such a way that it is easy to\n",
    "\n",
    "* add new models\n",
    "* vary model parameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
