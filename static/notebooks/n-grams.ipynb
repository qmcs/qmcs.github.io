{
 "metadata": {
  "name": "",
  "signature": "sha256:ee346899825c7ab994f471c4eabc74d13ed32bd5a994b136d42e7e45153ae1f5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Iterators"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A concept of iteration over containers is very powerfull. Python defines a protocol how iteration is performed. To see it in action, let's get the ASCII letters and enumarate them.\n",
      "\n",
      "Press shift+enter to execute a cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from string import lowercase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lowercase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'abcdefghijklmnopqrstuvwxyz'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``enumerate()`` enumerates a sequence of things. Appending ``?`` of ``??`` to a function, module or an object shows its help message."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "enumerate?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create an iterator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "enumerated_letters = enumerate(lowercase)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``next()`` returns the next value from an iterator, which in case of ``enumerate()`` are ``(index, value)`` pairs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(0, 'a')"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(1, 'b')"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way of accessing the values in a tuple is to assign all of them to variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "position, letter = next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we need to show something to a user which is a mix of text and data ``.format()`` is handy. Defining a string template with data placesholders and formating it with values avoid string concatenation using ``+``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'{letter} is enumerated as {position}'.format(letter=letter, position=position)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "'c is enumerated as 2'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In case a sequence of strings has to be joined use ``.join()``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ', '.join('{l} is enumerated as {p}'.format(l=l, p=p) for p, l in enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "d is enumerated as 3, e is enumerated as 4, f is enumerated as 5, g is enumerated as 6, h is enumerated as 7, i is enumerated as 8, j is enumerated as 9, k is enumerated as 10, l is enumerated as 11, m is enumerated as 12, n is enumerated as 13, o is enumerated as 14, p is enumerated as 15, q is enumerated as 16, r is enumerated as 17, s is enumerated as 18, t is enumerated as 19, u is enumerated as 20, v is enumerated as 21, w is enumerated as 22, x is enumerated as 23, y is enumerated as 24, z is enumerated as 25\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once an iterator is exhausted, a ``StopIteration`` exception is raised. However, it's possible to have infinite iterators."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(enumerated_letters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "StopIteration",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-10-6592de41862c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerated_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mStopIteration\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Bigrams\n",
      "\n",
      "Given a sequence of words (or an iterable), ``bigrams()`` returns (yields) its bigrams. Here is another way of defining an iterator (actually a generator):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "\n",
      "\n",
      "def bigrams(words):\n",
      "    \"\"\"Bigram generated from a seuence of words.\n",
      "    \n",
      "    :param iter words: the sequence of words\n",
      "    :returns: adjacent word pairs\n",
      "    \n",
      "    \"\"\"\n",
      "    # In the very beginning, ther is no previous word,\n",
      "    # but we start with a bigram (None, words[0]) to\n",
      "    # indicate that words[0] has been seen in the beginning\n",
      "    # of the text.\n",
      "    previous = None\n",
      "    \n",
      "    # We also need to append None to the end of the text.\n",
      "    # itertools.chain chains iterables togetner\n",
      "    # (yes, a list in this regard is an iterable, as a\n",
      "    # string is and many other things.\n",
      "    for word in chain(words, [None]):\n",
      "        # A bigram is a previous word and the current word.\n",
      "        # yield is used to pause an iterator, \"return\" a value\n",
      "        # to the caller code and restore callers execution.\n",
      "        yield previous, word\n",
      "        \n",
      "        previous = word\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check wheter it works. Note that we don't actually care wheter words is a seuence of strings, it might be a seuence of anything."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(bigrams([1, 2, 3, 4]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[(None, 1), (1, 2), (2, 3), (3, 4), (4, None)]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# N-grams\n",
      "\n",
      "It would be cool to have a general generator for n-grams."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import deque\n",
      "\n",
      "\n",
      "def ngrams(words, ngram_len=2):\n",
      "    \"\"\"Generate ngrmas from a sequence of word.\n",
      "    \n",
      "    :param iter words: the sequence of words\n",
      "    :param int ngram_len: the lenght of the ngrams to be generated\n",
      "    \n",
      "    :returns: ngrams\n",
      "    \n",
      "    \"\"\"\n",
      "    # collecions.deque might be seen as a list of limited size.\n",
      "    # If an element apended when a deque is full, the elements\n",
      "    # from the other side of the deque is removed keeping the\n",
      "    # constant length of the deque.\n",
      "    #\n",
      "    # Addend dummy tokens marking the beginning of the sequence.\n",
      "    ngram = deque([None] * ngram_len, maxlen=ngram_len)\n",
      "    \n",
      "    for word in chain(words, [None] * (ngram_len - 1)):\n",
      "        ngram.append(word)\n",
      "        yield tuple(ngram)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(ngrams('abcd', ngram_len=3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[(None, None, 'a'),\n",
        " (None, 'a', 'b'),\n",
        " ('a', 'b', 'c'),\n",
        " ('b', 'c', 'd'),\n",
        " ('c', 'd', None),\n",
        " ('d', None, None)]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Read a file word by word\n",
      "\n",
      "We have a generator that produces ngrmas, but we are not able to get a sequence of words from a corpus, which so far is just a text file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_words(f_name):\n",
      "    \"\"\"Read a file word by word.\"\"\"\n",
      "    with open(f_name) as f:\n",
      "        for line in f:\n",
      "            line.strip()\n",
      "            \n",
      "            # Tokenization is a difficult task,\n",
      "            # a word is anythin between two spaces.\n",
      "            for word in line.split():\n",
      "                yield word\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use  Alice's Adventures in Wonderland by Lewis Carroll as a corpus.\n",
      "\n",
      "Some other books are:\n",
      "\n",
      "* War and Peace by graf Leo Tolstoy http://eecs.io/static/notebooks/pg2600.txt 566,316 words\n",
      "* Crime and Punishment by Fyodor Dostoyevsky http://eecs.io/static/notebooks/pg2554.txt 206,528 words\n",
      "* Alice's Adventures in Wonderland by Lewis Carroll http://eecs.io/static/notebooks/pg11.txt 29,461 words\n",
      "* Clarissa Harlowe; or the history of a young lady \u2014 Volume 1 by Samuel Richardson http://eecs.io/static/notebooks/pg9296.txt 109,997 words\n",
      "* Clarissa Harlowe; or the history of a young lady \u2014 Volume 2 by Samuel Richardson http://eecs.io/static/notebooks/pg9798.txt 110,407 words\n",
      "* Clarissa Harlowe; or the history of a young lady \u2014 Volume 3 by Samuel Richardson http://eecs.io/static/notebooks/pg9881.txt 109,620 words\n",
      "\n",
      "We download it from the Internet ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlretrieve\n",
      "\n",
      "\n",
      "f_name, _ = urlretrieve('http://eecs.io/static/notebooks/pg11.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and store it somewhere"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "'/var/folders/j5/m6pcb_9n6c1gqssrbtzmdmcc0000gn/T/tmp0LsuU_.txt'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are ready to get a sequence of words from the corpus. It's too big to be shown here, so ony 10 words are shown."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import islice\n",
      "\n",
      "\n",
      "print ' '.join(islice(read_words(f_name), 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufeffProject Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll This\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can chain iterators as processing block of the information flow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for w1, w2 in islice(bigrams(read_words(f_name)), 10):\n",
      "    print w1, w2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None \ufeffProject\n",
        "\ufeffProject Gutenberg's\n",
        "Gutenberg's Alice's\n",
        "Alice's Adventures\n",
        "Adventures in\n",
        "in Wonderland,\n",
        "Wonderland, by\n",
        "by Lewis\n",
        "Lewis Carroll\n",
        "Carroll This\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Task: clean up the words\n",
      "\n",
      "Even though ```read_words()``` tokenizaion is very simple, we can filter out non letters. Lowercase words might be a good idea as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_words(words):\n",
      "    for word in words:\n",
      "        yield word.lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Counting ngrams\n",
      "\n",
      "It would be cool if we managed to pump the bigrams to a database. Then counting elements would be a metter of seconds (given that you know SQL. Luckily, there is Pandas which let process data frames (tables) the way we want http://pandas.pydata.org/pandas-docs/stable/groupby.html."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_frame = pd.DataFrame(ngrams(clean_words(read_words(f_name)), ngram_len=2), columns=('Word 1', 'Word 2'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_frame.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        None</td>\n",
        "      <td>    \ufeffproject</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    \ufeffproject</td>\n",
        "      <td> gutenberg's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> gutenberg's</td>\n",
        "      <td>     alice's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     alice's</td>\n",
        "      <td>  adventures</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  adventures</td>\n",
        "      <td>          in</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "        Word 1       Word 2\n",
        "0         None     \ufeffproject\n",
        "1     \ufeffproject  gutenberg's\n",
        "2  gutenberg's      alice's\n",
        "3      alice's   adventures\n",
        "4   adventures           in"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Count unique bigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_frame['count'] = 1  # Create a new column"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts = bigram_frame.groupby(('Word 1', 'Word 2')).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.sort('count', ascending=False, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>said</th>\n",
        "      <th>the</th>\n",
        "      <td> 207</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <th>the</th>\n",
        "      <td> 154</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
        "      <th>a</th>\n",
        "      <td> 101</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>  92</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <th>the</th>\n",
        "      <td>  84</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "               count\n",
        "Word 1 Word 2       \n",
        "said   the       207\n",
        "of     the       154\n",
        "in     a         101\n",
        "       the        92\n",
        "to     the        84"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Dictionary size"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = pd.DataFrame(clean_words(read_words(f_name)), columns=('Word', ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary['count'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = dictionary.groupby('Word').sum().sort('count', ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "5581"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 1777</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>and</th>\n",
        "      <td>  833</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <td>  782</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>a</th>\n",
        "      <td>  670</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <td>  610</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "      count\n",
        "Word       \n",
        "the    1777\n",
        "and     833\n",
        "to      782\n",
        "a       670\n",
        "of      610"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.plot().loglog()  # Check out Seaborn http://web.stanford.edu/~mwaskom/software/seaborn/ to get nicer plots."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEECAYAAADandTrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGTlJREFUeJzt3Xt0ldWZx/HvkwACQQ2gRS6BKEIrlmnaccQOg5wZrStW\nEWmxmFVAvLadoYuxavE2EKoWrWPRaql2EEKtcrNOFQoiKscqaIWKSAexoI1cFKjchCI1JHv+2McQ\nQgInOefkfc97fp+1spL95pw3T1j6sHneZ+9tzjlERCS75QUdgIiIpE7JXEQkApTMRUQiQMlcRCQC\nlMxFRCJAyVxEJAKUzEVEIkDJXEQkAjKSzM2swMxWmNlFmbi/iIgcLlMz8x8CczJ0bxERqSepZG5m\n081sm5mtqXe91MzWmdl6MxufuPY1YC3w1/SHKyIiDbFk9mYxs0HAPuBXzrn+iWv5wDvA+cAWYAVQ\nBnwbKAD6AZ8Aw5w2gBERyahWybzIOfeymRXXu3w2sME5VwlgZrOBoc652xPjK4C/KpGLiGReUsm8\nEd2BTXXGm4EBnw2cczNTuLeIiDRBKsk8pRm3mbkrrriC4uJiAAoLCykpKSEWiwEQj8cBNNZYY41z\nehyPx6moqACguLiYSZMm4Zwz6kmqZg6QKLPMr1MzPwcod86VJsa3ADXOuXuSvJ8qMCIiTWRmDSbz\nVFoTVwJ9zKzYzNoAI4BnmnKD8vLy2r+BRESkcfF4nPLy8ka/n2w3yyxgMNAZ2A5McM7NMLMLgfuB\nfOBR59zkZAPTzFxEpOkam5knXWZJNyVzEZGmy0SZJWUqs4iIJCctZZZM0MxcJLeYHTGZlGNoKEc2\nNjNPpTVRRKRJNIFLXlP/8lOZRUQkC6jMIiKhkCgPBB1G1mjszyuUD0BFRCQ9lMxFRFpYcXExL774\nYlrvqZq5iEgLa07J6Vg1c5xzgXz4Hy0iuSLM/89v3LjRDRs2zJ188smuc+fObuzYsa6mpsbdcccd\nrlevXu5zn/ucGz16tNuzZ49zzrmlS5e6Hj16HHaPXr16uRdeeME559zEiRPdZZdd5kaPHu2OP/54\nd+aZZ7qVK1c655wbOXKky8vLc+3atXMdOnRw9957b4MxNfbnlbh+RE5VmUVEclp1dTUXX3wxp556\nKu+//z4ffPABl19+OTNmzGDmzJnE43Hee+899u3bx9ixYxu9T/1Wwvnz51NWVsaePXu45JJLat/7\n2GOP0bNnTxYsWMDevXu58cYb0/J7KJmLSE57/fXX+fDDD7n33ntp164dbdq0YeDAgTz++OPccMMN\nFBcXU1BQwOTJk5k9ezY1NTVJ3XfQoEGUlpZiZowcOZLVq1dn9PcIdNFQeXk5sVisdg9fEcld6Vog\n2tTux02bNtGrVy/y8g6f23744Yf06tWrdtyzZ08OHjzItm3bkrpvly5dar9u3749Bw4coKam5oif\nk6x4PH7UZ4yBPwBVIhcR8Ek4HR9NVVRUxMaNG6murj7serdu3aisrKwdb9y4kVatWtGlSxcKCgrY\nv39/7feqq6v561+TP8O+OVsbxGKxoz4AVZlFRHLagAED6Nq1KzfffDP79+/nwIEDLFu2jLKyMqZM\nmUJlZSX79u3j1ltv5fLLLycvL4++ffty4MABFi5cSFVVFXfeeSd///vfk/6ZXbp04d13303r76Fk\nLiI5LS8vj/nz57NhwwZ69uxJUVER8+bN46qrrmLUqFGce+65nHbaabRv354HH3wQgBNPPJGpU6dy\nzTXX0KNHDzp06EBRUVHtPc3siNl33fEtt9zCnXfeSceOHfnpT3+alt9Dy/lFpEVoOX/TaDm/iEgO\nCvwBqFaAiogcm3ZNFJFQUJmlaVRmERHJQUrmIiIRoGQuIhIBSuYiIhGgA51FpMU0Zxm7JEcbbYlI\ni1AnS2qOtdGWWhNFRLKIWhNFRCJMyVxEJAKUzEVEIkDJXEQkApTMRUQiQMlcRCQClMxFRCJAyVxE\nJAJ0OIWISBbQ4RQiIhGiFaAiIhGmZC4iEgFK5iIiEaBkLiISAUrmIiIRoGQuIhIBSuYiIhGgZC4i\nEgFK5iIiEZD2ZG5mXzCzX5jZXDO7Ot33FxGRI2VsOb+Z5QGznXPfauT7Ws4vItJEKS3nN7PpZrbN\nzNbUu15qZuvMbL2Zja9zfQjwO2B2qoGLiMixJTUzN7NBwD7gV865/olr+cA7wPnAFmAFUOace7vO\n+552zg1t5J6amYuINFFjM/NWybzZOfeymRXXu3w2sME5V5n4AbOBoWb2OeAbQFtgaQoxi4hIkpJK\n5o3oDmyqM94MDHDOvQS8lMwNxowZQ3FxMQCFhYWUlJQQi8UAavc511hjjTXO5XE8HqeiogKgNl82\nJOkHoImZ+fw6ZZZvAqXOuWsT45H4ZP79JO+nMouISBNlYj/zLUBRnXERfnYuIiItLJVkvhLoY2bF\nZtYGGAE805Qb6Ng4EZHkxNNxbJyZzQIGA52B7cAE59wMM7sQuB/IBx51zk1ONjCVWY5UXQ0jRkCn\nTv6jc+eGP3fqBMcdF3S0IhKExsosOgM0RA4ehN/+FnbsgJ07G/+8cye0aXPshP/Z1yedBH36QH5+\n0L+hiKQqpdbETCkvLycWi9U+wc11rVrB8OHHfp1zsG9f48l+82Z4661D423b4OOP4aKLYMgQuOAC\nOP74zP8+IpI+8Xj8qGVpzcxzRGUlLFgAzzwDr74KAwf6xD5kCPTsGXR0IpIslVmk1scfw3PPwfz5\nsHAhdOsGl1ziE/tZZ0Ge9tIUCa1MtCamTN0swTjhBF/OmTkTtm6FqVOhqgrGjIHu3eGaa+Cpp3yJ\nRkTCIS3dLJmgmXk4vfuun7EvXgzLlvkHp//2b/5j0CDo0CHoCEVym8os0mSffgorVsCLL/qPFSvg\nS186lNwHDvRdNSLScpTMJWWffALLl/vEvmQJ7NoFU6b4Lhk74j8tEcmEUCbziRMnqjUxiz37LFx/\nPfTq5ZP6GWcEHZFIdH3Wmjhp0qTwJXPNzLNfVRX8/Odw110wciRMnAiFhUFHJRJdoexmkezXujX8\n53/C2rWwfz984QvwyCN+awIRaTmamUtarVoF//7vvsXx17+Gtm2DjkgkWkI5M1efefR8+csQj/t9\nYEpLYffuoCMSiQb1mUsgamr8w9GlS2HRIj9TF5HUhXJmLtGVlwf33w/f/rbvR1+3LuiIRKIt0F0T\nJdrMYPx4OOUUiMVg1iwtNBLJFJVZpEUsWuQfjG7Z4vdZ79HDfwwe7K8rwYskJ5SLhpTMc091td/c\na/Nm2LQJKirgnXfgvvv8ro1aSSpydKFM5loBKnBoJWmPHvDAA9CvX9ARiYSPVoBKVqiqgl/8Au64\nA+6+G666SrN0kYaEcmauZC71vf2232v9rLP8PusFBUFHJBIuSuaSNf72N/je9+CNN+Cyy/we6gUF\n8PWv64g7ESVzySrOwW9+A2vW+MOr//IXf/KRFgxLrlMyl6x28KDfxOvRR307o0iu0gpQyWqtWsFt\nt8GPfhR0JCLhpI22JGuMHOnLLa+8EnQkIi1PG21JpEybBvPm+QOnRXKRauYSCZ9+Cn36wHXXwWmn\nHdr3RT3pkiuUzCUyXnoJ5s713S2rV0P//n5bgHbtgo5MJPOUzCWSDhyAq6+G9evh6aeha9egIxLJ\nLHWzSCS1beuPpxs61K8afeGFoCMSCYZm5hIZzz8Po0fDJZf4enqnTr43/YtfhMLCoKMTSQ+VWSQn\nbN3qFxbt3g0ffeT3elm3Dq69Fm69FTp2DDpCkdQomUvO+vBDv+DojTdg1Sp1vkh2C2XNXIuGpCV0\n7epn61VV8OKLQUcj0jxaNCSS8Mgj8LvfwTPPBB2JSPOpzCI5b/9+v4XuH/4AvXsHHY1I84SyzCLS\nktq3h7FjYeBAGDXK19JFokIzc8kpzsF778HDD8OSJX416YknBh2VSPI0MxfBd7L07g0/+QkMGuQ/\nZs70e76IZDPNzCVn1dTAggXw4IN+tv7DH8L556ueLuGmB6AiR/HCC759cckSmDABvv/9oCMSaZiS\nuUgSKivhwguhe3e46y4YMCDoiEQOp5q5SBKKi+HNN2HECBg+HPbuDToikeRoZi7SiCuu8A9Mf/xj\n6NYt6GhEPM3MRZrovvv85/79QbtOSNhlZGZuZkOBi4ATgEedc0saeI1m5pIVli6FSy/1e6effjqc\ndBI88IAvyYi0tEAegJpZIfDfzrlrGviekrlkjX374OOP/YlGCxbAH//o90/P079tpYWlXGYxs+lm\nts3M1tS7Xmpm68xsvZmNr/e224GHmheySHh06ODr5oMHw913+33TX3016KhEDmnKvGIGUFr3gpnl\n45N1KdAPKDOzM8y7B1jknHszbdGKhEB+PgwZ4nvSRcIi6WTunHsZ2FXv8tnABudcpXOuCpgNDAXG\nAucBw83sO+kKViQsvvY1eO65oKMQOaRViu/vDmyqM94MDHDOfR948FhvHjNmDMWJp0iFhYWUlJQQ\ni8UAag+t0FjjMI5rauK89RaMGxfjpptgw4ZwxadxdMbxeJyKigqA2nzZkCY9ADWzYmC+c65/YvxN\noNQ5d21iPJJDyfxY99IDUMlq77wDFRV+G4B774WzzoJ+/XQsnWRWpvrMtwBFdcZF+Nm5SOR9/vMw\neTLMnQtz5vjSyyOPBB2V5KpUk/lKoI+ZFZtZG2AEkPShXDoDVKIgFoOFC/1WutOmBR2NRFU8XWeA\nmtksYDDQGdgOTHDOzTCzC4H7gXz8AqHJSd5PZRaJlOpqfyzd8OG+3PLVr8IXv6hedEkv7Zoo0gL+\n/GeYNw/WrIHly+Gf/gnuucevHBVJh8aSeardLCkpLy8nFovVPsEVyXZ9+8Jtt/mvP/nEb9J1zjk+\nqZ90EpSV+S129ZBUmioejx+1LK2ZuUiG7d0LixfDjh0wZQqMHAm33x50VJKtVGYRCYFNm+ArX4H5\n8/2MXaSpQrkFrrpZJNcUFcGMGX47gAkTYOPGoCOSbJG2bpZ008xcctmWLXDTTfDb38K770LXrkFH\nJNlCZRaREBo3Dn75S/joIygoCDoayQahLLOI5LoHHvAll969fVIXaS61JooE7Ikn4Nln4eqroarK\nf27bNuioJGzUmiiSJVauhGuv9S2MN90E3/0utG4ddFQSNqqZi2SBmhpYtAj+67/g/PPhJz8JOiIJ\nGyVzkSyyZYvf1+XAAfiP//C7M2qWLhDSB6DqMxdpWPfuvsNl9WpYtsyXXTT3yW3qMxfJcrt2wcCB\nsH27b2Xs3x8uvTToqCQooZyZi8ixdewIa9fCr37lyy4jRqiNUY6kmblIllm0CCZNgtdeCzoSCYJm\n5iIRcd55/vzRW2+FrVthz56gI5Iw0ANQkSzTpg28/DK88gqUlECPHnDHHbB7d9CRSSbpAahIxD3/\nvD/NaPVqWLoUzjwz6Igkk9RnLhJhBw/CD34A8bhP6jrJKLqUzEUirqYGiov9oRdz5wYdjWSKkrlI\nDti5E047ze/zokOko0ndLCI5oFMnGDPGrxiV3KKZuUjE7N7tZ+f5+f5h6KxZOskoSkI5M1drokj6\nFRbC5s1+1WhBgU/sjz0Gf/5z0JFJKtSaKJLjfvYzeOop+OADmDMHvvzloCOSVOgBqEgO+/RTf4LR\nypUwbBj86EfQKtBzxqS5QllmEZGW0aYNPPwwjB0Ljz8Ow4dDZWXQUUk6aWYukmNWrYJbbvH7pT/5\npO9Nl+yhmbmIAL5mPmMGnHwyfOMb8Ic/BB2RpIOSuUgO6toVHn0UvvQlX0t//vmgI5JUqcwiksN2\n7IAJE+D3v/fbAIwb588elfBSN4uINGjHDvjf/4Wnn/Ybdg0a5FeRdusWdGTSECVzETmq//s/eOIJ\neO45P0sfP97vlS7h0lgyD7TTtLy8nFgsRiwWCzIMEcEv/b/rLn949G23+W0Bpk2D444LOjIBvwL0\naCvmNTMXkSO8/jpccAF06OC3BpDwUGuiiCTt7LNh1y7YsgUeeijoaCQZSuYi0iAzuPtuX2pZuTLo\naORYVGYRkUZt3QrXXQfbt8NrrwUdjYC6WUSkmTZvhlNPhS5doHNnePNNnTEaJCVzEWm27dv9zov9\n+sHUqT6pl5YqqQdByVxEUnbzzbB+PSxcCO+9pxOMgqBkLiJpc+aZfrfFa6+FSy8NOprcotZEEUmb\n6dOhZ0+/BYCEg2bmItIsCxbA5ZfDKadA+/awfLlfZCSZ1WIzczM71cymmdm8dN9bRMLj61+H1avh\n2WfhwAGdXBS0tCdz59xfnHPXpPu+IhIueXnQuzecfjp8/vPwL//iD7xYsCDoyHJTUsnczKab2TYz\nW1PveqmZrTOz9WY2PjMhikjYPfmk73IpK4M//SnoaHJTsjPzGUBp3Qtmlg88lLjeDygzszPSG56I\nZIPjjvOz8tNPhylT/NF0X/kKrFgRdGS5I6lk7px7GdhV7/LZwAbnXKVzrgqYDQw1s05m9jBQotm6\nSG657jpfQ58+3bcurl4ddES5I5X9zLsDm+qMNwMDnHM7ge+mFJWIZKW2bf2sHKBPH5g71+/vMm4c\nHH98sLFFXSrJPOW+wjFjxlBcXAxAYWEhJSUltQdVfLYJu8Yaa5yd4759oV27GNOmwYknxunfP1zx\nZcs4Ho9TUVEBUJsvG5J0n7mZFQPznXP9E+NzgHLnXGlifAtQ45y7J8n7qc9cJAdcfDF85zswZEjQ\nkURDJvrMVwJ9zKzYzNoAI4BnUrifiERQ9+7wrW/BCSf4j2vUuJwRybYmzgKWA33NbJOZXemcOwiM\nBRYDa4E5zrm3m/LDy8vLa/85ISLRNHUqbNvmt9KdMwfeeSfoiLJTPB6nvLy80e9rOb+ItJhVq2DU\nKHj++UPXCgr0cLQpGiuzpPIANGXl5eXEYrHaor+IRFu3bvDxx1BS4sc1NX5fF20FcGzxePyolQzN\nzEUkMHv2QFGRT/CSHG2BKyKh07497N8PmtelTjNzEQlUhw5+G926R9CNGgUTJgQXU5ipZi4iobRh\nA+zde2i8ZAksXhxcPGGlmrmIZJUlS+Ceew7veJFDQjkzFxGpr6AAdu6E998/dC0/3y8+siNSmHxG\nZRYRCZUePXx3y7nnHrq2dSv8/vcwYEBwcQVNZRYRyXoXXAA33ug/5zq1JopI1mrb1p8zKo1TMheR\n0FMyPzaVWUQk9K680u/r0qPH4ddvugkGDw4mpqCEsptFD0BFJBnl5bBmzeHXKirgtddyJ5nrAaiI\nRNLtt/vyy+23Bx1Jy9IDUBGJlDZt4NNPg44iPJTMRSQrKZkfTitARSQrtW7tTy1asODI7+Xlwb/+\nK7Rr1/JxBUUPQEUkKw0YAEuXwsMPH/m9FStg+nS46KKWjytT9ABURHLOsGEwerT/HDV6ACoiOaN1\na6iqCjqKlqVkLiKR06qVkrmISNZr3RoOHgw6ipalZC4ikZOLM3O1JopI5LRuDa+/Dh07Hvu155zj\nD77IdmpNFJHIueACePxxeOKJo79u3Tq49FK4666WiSsVak0UEWnE5Mmwe7c/czRbqDVRRKSe/Hyo\nrg46ivRQMheRnKVkLiISAUrmIiIRoGQuIhIBSuYiIhGgZC4iEgFRSuZaASoiOSs/H954AyZNat77\ny8qgb9/0xtRcWgEqIjnrvPOgshJqapr+3mefhRNOaLlkrhWgIiIZcP31UFQEP/hBy/5crQAVEUmj\nvLzmzegzRclcRKQZ8vIgTMUFJXMRkWYw08xcRCTrqcwiIhIBKrOIiESAyiwiIhGgMouISASozCIi\nEgFhm5mnfTm/mRUAU4G/A3Hn3DGOVBURyT65UDP/BjDXOXcdcEkG7i8iErisLLOY2XQz22Zma+pd\nLzWzdWa23szGJy53BzYlvo7I5pIiIocLW5kl2Zn5DKC07gUzywceSlzvB5SZ2RnAZqCoifcXEckq\nWVlmcc69DOyqd/lsYINzrtI5VwXMBoYCTwHfNLOpwDPpDFZEJCzCVmZJ5QFo3XIK+Bn5AOfcfuCq\nlKISEQm5Vq3gySdh7dqgI/FSSeYp/51kZnXP94g75+Kp3lNEpCXccIP/yDQziwGxOpcmNvS6VJL5\nFg7Vxkl8vTnZNze0ubqIiBwuMcmN17lU3tDrUnlAuRLoY2bFZtYGGIFq5CIigUi2NXEWsBzoa2ab\nzOxK59xBYCywGFgLzHHOvZ25UEVEpDGBnQEqIiLpoz5wiTwzm2Jm4+qMF5vZ/9QZ32dm1zfjvjEz\nm5+uOEVSoWQuueAV4J8BzCwP6Ixf6PaZrwLLjnWTxHtFQkn/cUoueBWfsAHOBP4E7DWzQjM7DjgD\nKDSzVWb2lpk9mnioj5lVmtndZvZH4LLEFhZvJ8bDgvhlRBqiZC6R55z7ADhoZkX4pP4q8Hri67OA\n9cA04DLn3D/gW3a/99nbgY+cc/8IPA38Erg4MT6FNKy3EEkHJXPJFcvxpZZ/xifzVxNffxW/PuI9\n59yGxGtnAufWee+cxOcvAH9xzr2bGP8a0HoJCQUlc8kVy4CBQH9gDfAah5J7nMOTsnH4jPtvjdxT\niVxCQ8lccsVy4GJgh/N2AYX4mflvgGIz65147SjgpQbusS7xutMS47IMxyySNCVzyRV/wnexvFbn\n2lvAbufcFuBKYJ6ZvQUcBB5OvKZ2hu6cOwBcB/wu8QB0G6qZS0ho0ZCISARoZi4iEgFK5iIiEaBk\nLiISAUrmIiIRoGQuIhIBSuYiIhGgZC4iEgFK5iIiEfD/r3KZ07uhx9AAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x115f79190>"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Count bigrams that were seen more than n times"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bigram_counts[bigram_counts['count'] > 5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "498"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bigram_counts[bigram_counts['count'] > 4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "672"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Joint probability"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts['Joint probability'] = bigram_counts['count'] / bigram_counts['count'].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>Joint probability</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>said</th>\n",
        "      <th>the</th>\n",
        "      <td> 207</td>\n",
        "      <td> 0.007026</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <th>the</th>\n",
        "      <td> 154</td>\n",
        "      <td> 0.005227</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
        "      <th>a</th>\n",
        "      <td> 101</td>\n",
        "      <td> 0.003428</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>  92</td>\n",
        "      <td> 0.003123</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <th>the</th>\n",
        "      <td>  84</td>\n",
        "      <td> 0.002851</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "               count  Joint probability\n",
        "Word 1 Word 2                          \n",
        "said   the       207           0.007026\n",
        "of     the       154           0.005227\n",
        "in     a         101           0.003428\n",
        "       the        92           0.003123\n",
        "to     the        84           0.002851"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.loc['to'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>Joint probability</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 84</td>\n",
        "      <td> 0.002851</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>be</th>\n",
        "      <td> 49</td>\n",
        "      <td> 0.001663</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>herself,</th>\n",
        "      <td> 25</td>\n",
        "      <td> 0.000849</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>see</th>\n",
        "      <td> 23</td>\n",
        "      <td> 0.000781</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>get</th>\n",
        "      <td> 18</td>\n",
        "      <td> 0.000611</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "          count  Joint probability\n",
        "Word 2                            \n",
        "the          84           0.002851\n",
        "be           49           0.001663\n",
        "herself,     25           0.000849\n",
        "see          23           0.000781\n",
        "get          18           0.000611"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Condiitonal probability"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>Joint probability</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 1</th>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>said</th>\n",
        "      <th>the</th>\n",
        "      <td> 207</td>\n",
        "      <td> 0.007026</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>of</th>\n",
        "      <th>the</th>\n",
        "      <td> 154</td>\n",
        "      <td> 0.005227</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\" valign=\"top\">in</th>\n",
        "      <th>a</th>\n",
        "      <td> 101</td>\n",
        "      <td> 0.003428</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>  92</td>\n",
        "      <td> 0.003123</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>to</th>\n",
        "      <th>the</th>\n",
        "      <td>  84</td>\n",
        "      <td> 0.002851</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "               count  Joint probability\n",
        "Word 1 Word 2                          \n",
        "said   the       207           0.007026\n",
        "of     the       154           0.005227\n",
        "in     a         101           0.003428\n",
        "       the        92           0.003123\n",
        "to     the        84           0.002851"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts['Word 1 count'] = dictionary.loc[bigram_counts.index.get_level_values('Word 1')]['count'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts['Conditional probability'] = bigram_counts['count'] / bigram_counts['Word 1 count']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts.loc['she'].sort('Conditional probability', ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>count</th>\n",
        "      <th>Joint probability</th>\n",
        "      <th>Word 1 count</th>\n",
        "      <th>Conditional probability</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Word 2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>had</th>\n",
        "      <td> 57</td>\n",
        "      <td> 0.001935</td>\n",
        "      <td> 518</td>\n",
        "      <td> 0.110039</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>was</th>\n",
        "      <td> 51</td>\n",
        "      <td> 0.001731</td>\n",
        "      <td> 518</td>\n",
        "      <td> 0.098456</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>said</th>\n",
        "      <td> 28</td>\n",
        "      <td> 0.000950</td>\n",
        "      <td> 518</td>\n",
        "      <td> 0.054054</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>went</th>\n",
        "      <td> 28</td>\n",
        "      <td> 0.000950</td>\n",
        "      <td> 518</td>\n",
        "      <td> 0.054054</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>could</th>\n",
        "      <td> 19</td>\n",
        "      <td> 0.000645</td>\n",
        "      <td> 518</td>\n",
        "      <td> 0.036680</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "        count  Joint probability  Word 1 count  Conditional probability\n",
        "Word 2                                                                 \n",
        "had        57           0.001935           518                 0.110039\n",
        "was        51           0.001731           518                 0.098456\n",
        "said       28           0.000950           518                 0.054054\n",
        "went       28           0.000950           518                 0.054054\n",
        "could      19           0.000645           518                 0.036680"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get two corpora drawen from a different domain (for example, Russian classics, and novels about Clarissa), and divide each to a training and a test set. Build language models based on the training data for each domain. Then calcualte the corss-entropy figures for the test sets using both the language model trained on that domain, and the other language model. How much do the cross-entropy estimates differ?\n",
      "\n",
      "`This is Exercise 6.8 from Manning, Christopher D. \"Foundations of statistical natural language processing\". Ed. Hinrich Sch\u00fctze. MIT press, 1999.`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Experiment with different tokenisation methods. Try to implement the experiments in such a way that it is easy to\n",
      "\n",
      "* add new models\n",
      "* vary model parameters\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}